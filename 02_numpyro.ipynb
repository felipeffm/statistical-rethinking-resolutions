{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an introduction to the NumPyro and JAX Numpy methods used to resolve the exercises in chapter 2 of the book Statistical Rethinking. There are many other usefull functions and method that can be learned at the [official numpyro documentation](https://num.pyro.ai/en/latest/index.html#introductory-tutorials).JAX Numpy has the same syntax as NumPy but is usually faster. NumPyro has some exciting modules to analyze models and distributions with friendly syntax. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "\n",
    "- The tutorial covers\n",
    "    - Array declaring\n",
    "    - Simple algebric expressions\n",
    "    - Filter array based on condition\n",
    "    - Declaring distributions\n",
    "    - Sample from distribuitions\n",
    "    - Modeling\n",
    "        - Apply Auto Laplace Approximation in a defined model\n",
    "        - Apply Stochastic Variational Inference from a Auto Laplace Approximation\n",
    "        - Use the result of Stochastic Variational Inference to posteriori sample \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module `jax.numpy`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`jax.numpy` is an API for executing commands efficiently with the jax library still with NumPy syntax. Below comparing NumPy and jax.numpy syntaxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "# Declare an array\n",
    "arr = np.array([0.0, 3, 8, 9, 0])\n",
    "arr_j = jnp.array([0.0, 3, 8, 9, 0])\n",
    "\n",
    "# Sum elements of array\n",
    "sum_arr = np.sum(arr)\n",
    "sum_arrj = jnp.sum(arr)\n",
    "\n",
    "# Exponentiate a number\n",
    "a = np.exp(1)\n",
    "ej = jnp.exp(1) \n",
    "\n",
    "# Exponentiate an array\n",
    "exp_arr = np.exp(arr)\n",
    "exp_arr_j = jnp.exp(arr_j)\n",
    "\n",
    "# Conditionally change values in an array\n",
    "and_arr = jnp.where(arr_j < 0.5, 0, 1)\n",
    "cond_arrj = np.where(arr < 0.5, 0, 1)\n",
    "\n",
    "# Create a vector with sequential values\n",
    "seq = np.linspace(start=0, stop=1, num=100)\n",
    "seq_j = jnp.linspace(start=0, stop=1, num=100)\n",
    "\n",
    "# Create a vector with repeated values\n",
    "rep = np.repeat(1,100)\n",
    "rep_j = jnp.repeat(1,100)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to do `jax.numpy` operations directly in a NumPy vector, for example, replacing values based on conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "and_arr = jnp.where(arr < 0.5, 0, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`jax.numpy` is way faster than `numpy` for large operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420 ms ± 21.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit jnp.linspace(start=0, stop=1, num=1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.48 s ± 355 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.linspace(start =0, stop=1, num=1000000000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module `numpyro`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use `numpyro`, start configuring which hardware will execute the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro\n",
    "\n",
    "numpyro.set_platform(\"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaring distributions in `numpyro` is simple: the distribution parameters are the arguments. Then, processed values of the distribution can be accessed with methods and functions.\n",
    "\n",
    "For example, consider the Binomial distribution. \n",
    "\n",
    "$P(x) = (\\frac{n!}{(n-x)! x!})p^{x}(1-p)^{n-x}$\n",
    "\n",
    "To describe a binomial curve of the equation above, we need the total count of events `n`, the positive events `x`, and the probability `p` of getting success in one trial. These are the parameters to calculate a binomial distribution in numpyro. For example, if the binomial distribution was defined considering 9 events with 50% of probability, we can declare it as: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro.distributions as dist\n",
    "\n",
    "n=9\n",
    "p=0.5\n",
    "\n",
    "# Considering 9 events with a 50% probability\n",
    "binomial_dist = dist.Binomial(total_count=n, probs=p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the probability given some number of positive events we can call the method `.log_prob`. The method retrive the log of the probability of the declared distribution. For example, to get the log probability of 6 positive outcomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_events = 6\n",
    "log_prob = binomial_dist.log_prob(positive_events)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But usually, what we need is the actual probability, not the log of it. So it's possible to exponentiate and get the log with `jax.numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = jnp.exp(log_prob)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now that you have a distribution, how do you take samples from it? <br>Call the python object containing the distribution and the method `sample` with the first argument concerning the seed and the second argument as the total number of samples.</br> <br>For example, extract 1000 samples and store them in the vector `samples`:</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro \n",
    "from jax import random\n",
    "\n",
    "samples = binomial_dist.sample(random.PRNGKey(0), (1000,))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each value in the vector 'samples' corresponds to the total positive events in 9 occurrences given the binomial distribution previously defined. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>But when defining a model, the parameter of a distribution can be another distribution. To deal with it, we can declare the relationship between distributions in an algebraic form in a python function. </br>For example, suppose we want to define a Binomial distribution where the probability `p` of getting success in a trial follows a uniform distribution:\n",
    "<br></br>\n",
    "$\n",
    "\\newline\n",
    "P(x) \\backsim Binomial(n, p)\n",
    "\\newline\n",
    "p \\backsim Uniform(0,1)\n",
    "$\n",
    "<br></br>\n",
    "in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(n:int, x:int):\n",
    "    \"\"\"Declare a binomial distribution with the probability parameter as a uniform distribution\n",
    "\n",
    "    Args:\n",
    "        n (int): total count of events\n",
    "        x (int): total count of positive outcomes\n",
    "    \"\"\"    \n",
    "    p = numpyro.sample(name=\"p\", fn=dist.Uniform(0, 1))\n",
    "    numpyro.sample(name=\"x\", fn=dist.Binomial(n, p), obs=x)\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when declaring the related distributions, we didn't use the method `.sample ` from the distribution, but the method `numpyro.sample` where there is no argument defining the number of samples. Still, we can declare the observed values in the argument `obs`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the correct model declared in a function to calculate the posteriori, we need to\n",
    "\n",
    "1. Define the posteriori approximation;\n",
    "2. Define optimization;\n",
    "3. Optimize;\n",
    "4. Take samples of posteriori.\n",
    "\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1689.82it/s, init loss: 2.5989, avg. loss [951-1000]: 2.5494]\n"
     ]
    }
   ],
   "source": [
    "import numpyro.optim as optim\n",
    "from numpyro.infer import SVI, Trace_ELBO\n",
    "from numpyro.infer.autoguide import AutoLaplaceApproximation\n",
    "from jax import random\n",
    "\n",
    "# 1. Define the posteriori approximation\n",
    "guide = AutoLaplaceApproximation(model)\n",
    "\n",
    "# 2. Define optimization\n",
    "svi = SVI(model, guide, optim.Adam(1), Trace_ELBO(), n=6, x=3)\n",
    "\n",
    "# 3. Optimize\n",
    "svi_result = svi.run(random.PRNGKey(0), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Take samples of posteriori\n",
    "params = svi_result.params\n",
    "samples = guide.sample_posterior(random.PRNGKey(0), params, (1000,))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, with the samples we can analyse results with `numpyro.diagnostics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.5%     94.5%     n_eff     r_hat\n",
      "         p      0.50      0.15      0.50      0.28      0.77    954.19      1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numpyro.diagnostics.print_summary(samples, prob=0.89, group_by_chain=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (main, Nov 24 2022, 19:45:47) [GCC 12.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
